<!-- filename: 05_Ausgewaehlte_Forschungsmethoden_im_Forschungsprozess.md -->
<!-- title: Ausgewählte Forschungsmethoden im Forschungsprozess -->

Abweichend von der häufig gewählten oben genannten Unterscheidung von quantitativen und qualitativen Vorgehensweisen werden wir im Folgenden auf unterschiedliche Forschungsmethoden hinweisen, die wir im Hinblick auf ihre Verortung im Forschungsprozess darstellen.

## Verfahren der Datenerhebung

Es gibt zahlreiche Verfahren, beim technologiegestützten Lehren und Lernen Daten zu erheben. Zunächst ist hier die **Beobachtung** zu nennen. Forscher/innen beobachten dabei unter kontrollierten Bedingungen das Verhalten von Lerner/innen, auch mit Unterstützung von Video und anderen technischen Hilfsmitteln, oder erfassen automatisiert Daten (z.B. durch Tracking). Eine weitere Datenerhebungsform sind **Befragungen**, die (fern-)mündlich oder schriftlich erfolgen können (z.B. mit einem Web-Fragebogen). Dabei können Einzelpersonen oder auch Gruppen adressiert werden (z.B. in Fokusgruppen-Interviews). Eine wichtige Unterscheidung ist dabei die Form der Beantwortung oder Beobachtung: Werden offene Fragen gestellt beziehungsweise Beobachtungskategorien oder Antwortoptionen („standardisiertes Verfahren“) vorgeben? Eine Sonderform einer Befragung kann ein **Test** sein (z.B. als Persönlichkeitstest). Tests werden jedoch auch in der angewandten Informatik durchgeführt, wenn bestimmte Technologien nach vorher definierten Kriterien geprüft werden sollen (z.B. Performancetest).

Häufig wird versucht, mit Forschung einen bestimmten **Zustand zu beschreiben**, wobei in aller Regel versucht wird, nicht in das System einzugreifen. Besonders spannend wird es immer dann, wenn versucht wird, **Unterschiede oder Zusammenhänge** festzustellen, beispielsweise ob unterschiedliche Gruppen oder Technologien unterschiedliche Ergebnisse liefern, ob Verhalten oder Leistungen durch unterschiedliche Interventionen beeinflusst werden oder wenn Zusammenhänge zwischen Merkmalen untersucht werden sollen. Hierzu müssen in aller Regel Daten zu mehreren Variablen erhoben werden, häufig auch zu mehreren Zeitpunkten oder in verschiedenen Gruppen und mit verschiedenen Bedingungen. Als „Königsweg“ eines naturwissenschaftlich orientierten Zugangs ist dabei das **Experiment** zu bezeichnen. Darunter wird ein Versuch verstanden, bei dem eine Größe, die „unabhängige Variable“, systematisch verändert und so überprüft wird, wie sie das Ergebnis, die sogenannte „abhängige Variable“, beeinflusst. Die Herausforderung dabei ist, alle anderen Variablen „unter Kontrolle zu haben“. Sollen Experimente zum Lernen und Lehren durchgeführt werden, sind häufig Abstriche bei den idealen Experimentbedingungen zu machen. Häufig können sie nicht unter Laborbedingungen, unter denen alle Variablen „unter Kontrolle sind“, durchgeführt werden, sondern nur im „Feld“, das heißt zum Beispiel in einem Klassenzimmer.

Auch ist es oft (aus ethischen Gründen) nicht möglich, Teilnehmer/innen an Experimenten „zufällig“ auszuwählen oder Gruppen zuzuteilen, es handelt sich dann um „Quasiexperimente“. Die Voraussetzungen eines experimentellen Designs sind beim Lernen und Lehren mit Technologien nur selten zu realisieren. In der Forschungspraxis ist es oft schwierig, Vergleichsgruppen zu bilden. So sind die Unterschiede in zwei Schulklassen (Lehrer/innen, Schüler/innen, Verteilungen) oft schon zu groß, um Wirkungen zweier unterschiedlicher Interventionen beurteilen zu können. Die Feldstudie ist zwar im Forschungsbereich eine unerlässliche Vorgehensweise, da die Ergebnisse oft vom Laborversuch deutlich abweichen, aber umgekehrt auch viel schwieriger zu systematisieren. Sofern es nur um reine Technologien geht, beispielsweise um Performancetests unter bestimmten Bedingungen, gibt es diese Schwierigkeiten nicht.

## Verfahren der Auswertung

Bevor Daten ausgewertet werden, müssen die erhobenen Daten in aller Regel erst aufbereitet werden. Dann liegen sie in unterschiedlichen Formaten vor, beispielsweise als Texte, Tabellen oder auch als Foto- oder Videomaterial. Es gibt unterschiedliche Auswertungsmöglichkeiten, die jedoch auch von den spezifischen Materialien abhängen.

So gibt es für Daten, die in Form von Zahlen vorliegen, zunächst einmal die Möglichkeit der **quantitativen Auswertungsmöglichkeiten**. Deskriptive statistische Verfahren geben dabei einen Überblick über Verteilungen, beispielsweise Durchschnittswerte oder Rangreihen. Die Berechnung des Korrelationskoeffizienten ermöglicht so die Überprüfung, ob zwei Datensätze statistisch zusammenhängen. Die Clusteranalyse ist ein algorithmisches Verfahren, das auf „Häufelungen“ von Daten mit ähnlichen Merkmalsausprägungen hinweisen kann. Die Soziale-Netzwerk-Analyse wertet beispielsweise Vernetzungsstrukturen im Hinblick auf entscheidende Knoten im Netzwerk der Beziehungen oder Kommunikationsflüsse aus. Bei Vergleichen von Datensätzen, beispielsweise Gruppenvergleiche oder Prä- und Postdaten, kommen sogenannte inferenzstatistische Verfahren zum Einsatz. Diese erlauben Aussagen darüber, ob Unterschiede in den Gruppen durch den Zufall erklärt werden können oder statistisch bedeutsam sind. Bei sogenannten „Zusammenhangstudien“ wird versucht zu klären, inwieweit zwei Faktoren voneinander abhängen. Hier kann beispielweise das statistische Zusammenhangsmaß des Korrelationskoeffizienten berechnet werden. Solche Verfahren werden auch bei explorativen Auswertungen eingesetzt, um beispielsweise auf besondere Zusammenhänge aufmerksam zu werden (vgl. Kapitel #analytics).

Bei **qualitativ orientierten Verfahren** werden Daten im Hinblick auf inhaltliche Aspekte ausgewertet, beispielsweise werden Text- und Inhaltsanalysen im Hinblick auf bestimmte Motive, Argumentationsstrukturen, Muster (engl. Pattern) oder Aussagen hin angefertigt. Manchmal werden diese Kriterien auch erst während der Auswertung entwickelt. So beschreibt das Verfahren der „Grounded Theory“ (Glaser & Strauss, 1967) die Entwicklung und Entstehung von Theorien auf Grundlage der Auswertung von qualitativen Daten (in der Regel Texten). Gruppen können dabei verglichen werden, indem Besonderheiten identifiziert werden. Fallstudienanalysen versuchen beispielsweise häufig, Erfolg- und oder Misserfolgskriterien von Unternehmungen zu identifizieren.

## Verfahren der Entwicklung

Schließlich werden auch in der systematischen Entwicklung von neuartigen Konzepten und Systemen zahlreiche unterschiedliche Methoden eingesetzt, die mehr oder weniger genau vorschreiben, wie diese Entwicklung stattfinden soll, um die angestrebten positiven Ergebnisse zu erhalten, um besonders ökonomisch voran zu kommen oder auch, um besonders innovative Verfahren zu erhalten.

In der angewandten Informatik sind hier Prinzipien wie die iterative Softwareentwicklung, Prototyping, Analysen von Einsatzpotentialen oder auch nutzer-/nutzerinnen-zentrierten- Anwendungsentwicklungen zu nennen, wobei Letztere beispielsweise mit Hilfe der Persona-Methode gut zu den unterschiedlichen Anforderungen und Nutzergruppen passen. Auch gibt es zahlreiche Vorschläge, wie man zu gelungenen Lernumgebungen und -materialien gelangt, zum Beispiel das ADDIE- oder das ARCS-Modell oder indem man Architekturen solcher Informationssysteme entwirft. Auch gibt es Innovationsentwicklungsverfahren wie Lead-User-Workshops, die hier Anleitungen geben können. Spezielle Methoden in der Usability-Forschung (zum Beispiel Thinking Aloud oder Heuristische Evaluation) helfen, speziell die Mensch-Maschine-Interaktion besser zu verstehen (siehe Kapitel #usability). Schließlich ermöglichen unterschiedliche Evaluationsmethoden, die Entwicklung zu optimieren oder abschließend auf Stärken und Schwächen hinzuweisen.

<blockquote style="background: #FFEBEE; border-left: 10px solid #F44336">

### ?

Nehmen Sie die von Ihnen eingangs angefertigte Sammlung von Forschungsmethoden zur Hand. Welchem der drei skizzierten Forschungszugänge lassen sie sich zuordnen? Welche der hier genannten Forschungszugänge und Forschungsmethoden haben Sie *nicht* berücksichtigt?

</blockquote>
